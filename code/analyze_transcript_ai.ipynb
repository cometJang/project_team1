{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3bb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install python-dotenv langchain-google-genai pydantic tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41162d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # OS 환경변수\n",
    "import re  # 정규식\n",
    "import json  # JSON 처리\n",
    "import pandas as pd  # 판다스\n",
    "from collections import defaultdict  # 기본값 딕셔너리\n",
    "from typing import Optional, List, Dict, Any  # 타입 힌트\n",
    "\n",
    "from dotenv import load_dotenv  # .env 로더\n",
    "from pydantic import BaseModel, ValidationError  # Pydantic\n",
    "from tqdm import tqdm  # 진행바\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # Gemini\n",
    "from langchain_core.prompts import ChatPromptTemplate  # 프롬프트 템플릿\n",
    "\n",
    "# =========================\n",
    "# 0) ENV 로드\n",
    "# =========================\n",
    "load_dotenv(\"/content/drive/MyDrive/project_team1/.env\")  # ✅ .env 로드\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")  # ✅ 키 로드\n",
    "if not GEMINI_API_KEY:  # 키 없으면\n",
    "    raise ValueError(\"❌ GEMINI_API_KEY가 없습니다. project_team1/.env를 확인하세요.\")  # 중단\n",
    "\n",
    "# =========================\n",
    "# 1) 트랜스크립트 파싱\n",
    "# =========================\n",
    "def parse_transcript(transcript_path: str) -> List[Dict[str, str]]:  # 트랜스크립트 파싱 함수\n",
    "    dialogues = []  # 결과 리스트\n",
    "    current_speaker = \"UNKNOWN\"  # 현재 화자\n",
    "    current_text = []  # 누적 텍스트\n",
    "\n",
    "    speaker_time_pattern = re.compile(r'^(SPEAKER_\\d+)\\s+(\\d{2}:\\d{2}:\\d{2})$')  # SPEAKER+시간\n",
    "    time_only_pattern = re.compile(r'^(\\d{2}:\\d{2}:\\d{2})$')  # 시간만\n",
    "\n",
    "    with open(transcript_path, \"r\", encoding=\"utf-8\") as f:  # 파일 열기\n",
    "        lines = f.readlines()  # 라인 읽기\n",
    "\n",
    "    for line in lines:  # 반복\n",
    "        line = line.strip()  # 공백 제거\n",
    "        if not line:  # 빈 줄이면\n",
    "            continue  # 스킵\n",
    "\n",
    "        speaker_match = speaker_time_pattern.match(line)  # 매칭\n",
    "        time_match = time_only_pattern.match(line)  # 매칭\n",
    "\n",
    "        if speaker_match:  # 새 화자 시작\n",
    "            if current_text:  # 누적이 있으면\n",
    "                dialogues.append({\"speaker\": current_speaker, \"text\": \" \".join(current_text)})  # 저장\n",
    "                current_text = []  # 초기화\n",
    "            current_speaker = speaker_match.group(1)  # 화자 갱신\n",
    "\n",
    "        elif time_match:  # 시간만(세그먼트 구분)\n",
    "            if current_text:  # 누적이 있으면\n",
    "                dialogues.append({\"speaker\": current_speaker, \"text\": \" \".join(current_text)})  # 저장\n",
    "                current_text = []  # 초기화\n",
    "\n",
    "        else:  # 일반 텍스트\n",
    "            current_text.append(line)  # 누적\n",
    "\n",
    "    if current_text:  # 마지막 누적 처리\n",
    "        dialogues.append({\"speaker\": current_speaker, \"text\": \" \".join(current_text)})  # 저장\n",
    "\n",
    "    return dialogues  # 반환\n",
    "\n",
    "# =========================\n",
    "# 2) Config 로드 + Regex 분석(JSON)\n",
    "# =========================\n",
    "def load_config(config_path: str) -> Dict:  # config 로드\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as f:  # 파일 열기\n",
    "        return json.load(f)  # 로드\n",
    "\n",
    "def analyze_text_regex(dialogues: List[Dict[str, str]], config: Dict) -> Dict:  # regex 기반 카운트 분석\n",
    "    keyword_map = {}  # 키워드 맵\n",
    "\n",
    "    if \"emotion_polarity\" in config:  # 감정 설정\n",
    "        if \"positive\" in config[\"emotion_polarity\"]:\n",
    "            keyword_map[\"positive\"] = config[\"emotion_polarity\"][\"positive\"][\"keywords\"]\n",
    "        if \"negative\" in config[\"emotion_polarity\"]:\n",
    "            keyword_map[\"negative\"] = config[\"emotion_polarity\"][\"negative\"][\"keywords\"]\n",
    "\n",
    "    if \"attention\" in config:  # attention 설정\n",
    "        if \"mention_x\" in config[\"attention\"]:\n",
    "            keyword_map[\"mention_x\"] = config[\"attention\"][\"mention_x\"][\"keywords\"]\n",
    "        if \"mention_other\" in config[\"attention\"]:\n",
    "            keyword_map[\"mention_other\"] = [\"해은\", \"규민\", \"나연\", \"희두\", \"원빈\", \"지수\", \"태희\", \"지연\", \"나언\", \"현규\", \"지현\"]\n",
    "\n",
    "    if \"initiative\" in config:  # initiative 설정\n",
    "        keyword_map[\"initiative\"] = config[\"initiative\"][\"keywords\"]\n",
    "\n",
    "    total_counts = defaultdict(int)  # 전체 카운트\n",
    "    speaker_stats = defaultdict(lambda: defaultdict(int))  # 화자별 카운트\n",
    "\n",
    "    for entry in dialogues:  # 반복\n",
    "        speaker = entry[\"speaker\"]  # 화자\n",
    "        text = entry[\"text\"]  # 텍스트\n",
    "\n",
    "        for category, keywords in keyword_map.items():  # 카테고리 반복\n",
    "            for kw in keywords:  # 키워드 반복\n",
    "                if kw in text:  # 포함되면\n",
    "                    c = text.count(kw)  # 횟수\n",
    "                    total_counts[category] += c  # 누적\n",
    "                    speaker_stats[speaker][category] += c  # 누적\n",
    "\n",
    "    return {  # 결과 반환\n",
    "        \"summary\": dict(total_counts),  # dict 변환\n",
    "        \"by_speaker\": {k: dict(v) for k, v in speaker_stats.items()},  # dict 변환\n",
    "    }\n",
    "\n",
    "def save_json(obj: Any, path: str) -> None:  # JSON 저장\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:  # 파일 열기\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)  # 저장\n",
    "\n",
    "# =========================\n",
    "# 3) Gemini: 스키마\n",
    "# =========================\n",
    "class SpeakerMapping(BaseModel):  # 화자 매핑 스키마\n",
    "    speaker_id: str  # SPEAKER_XX\n",
    "    real_name: str  # ✅ 반드시 후보 중 하나(Unknown 금지)\n",
    "    reason: str  # 근거\n",
    "    confidence: float  # 확신도(0~1)\n",
    "\n",
    "class SpeakerMappingList(BaseModel):  # 리스트 스키마\n",
    "    mappings: List[SpeakerMapping]  # 매핑 리스트\n",
    "\n",
    "class DialogueAnalysis(BaseModel):  # 대화 분석 스키마\n",
    "    target_person: Optional[str] = \"None\"  # 대상 인물\n",
    "    sentiment: str  # positive/negative/neutral\n",
    "    category: str  # emotion/attention/initiative\n",
    "    summary: str  # 요약\n",
    "\n",
    "# =========================\n",
    "# 4) 캐시: 화자 매핑 저장/불러오기(JSON)\n",
    "# =========================\n",
    "def load_mapping_cache(cache_path: str) -> Optional[Dict[str, Any]]:  # 캐시 로드\n",
    "    if not os.path.exists(cache_path):  # 없으면\n",
    "        return None  # None\n",
    "    with open(cache_path, \"r\", encoding=\"utf-8\") as f:  # 열기\n",
    "        return json.load(f)  # 로드\n",
    "\n",
    "def save_mapping_cache(cache_path: str, mapping_obj: Dict[str, Any]) -> None:  # 캐시 저장\n",
    "    with open(cache_path, \"w\", encoding=\"utf-8\") as f:  # 열기\n",
    "        json.dump(mapping_obj, f, ensure_ascii=False, indent=2)  # 저장\n",
    "\n",
    "# =========================\n",
    "# 5) 샘플 선별: 정보량 높은 대사만 사용(정확도 업)\n",
    "# =========================\n",
    "def build_speaker_samples(dialogues: List[Dict[str, str]], max_samples: int = 20, min_len: int = 20) -> Dict[str, List[str]]:  # 샘플 생성\n",
    "    speaker_samples = {}  # 결과 dict\n",
    "\n",
    "    for d in dialogues:  # 반복\n",
    "        sid = d[\"speaker\"]  # 화자\n",
    "        text = d[\"text\"].strip()  # 텍스트\n",
    "\n",
    "        if len(text) < min_len:  # 너무 짧으면\n",
    "            continue  # 스킵\n",
    "\n",
    "        score = 0  # 점수\n",
    "        if re.search(r\"[0-9]\", text):  # 숫자 단서\n",
    "            score += 1\n",
    "        if re.search(r\"(오빠|언니|누나|형)\", text):  # 호칭 단서\n",
    "            score += 2\n",
    "        if re.search(r\"(집|회사|학교|공항|한국|연대|북문)\", text):  # 장소 단서\n",
    "            score += 1\n",
    "        if re.search(r\"(헤어|만나|연락|데이트|사귀|좋아|싫어)\", text):  # 관계 단서\n",
    "            score += 1\n",
    "\n",
    "        if score < 1:  # 단서 부족이면\n",
    "            continue  # 스킵\n",
    "\n",
    "        speaker_samples.setdefault(sid, [])  # 초기화\n",
    "        if len(speaker_samples[sid]) >= max_samples:  # 상한이면\n",
    "            continue  # 스킵\n",
    "\n",
    "        speaker_samples[sid].append(text)  # 추가\n",
    "\n",
    "    return speaker_samples  # 반환\n",
    "\n",
    "# =========================\n",
    "# 6) 화자 식별(Unknown 금지): 반드시 후보 중 하나로 찍기\n",
    "#    - 캐시에 {speaker_id: {name, confidence, reason}} 저장\n",
    "# =========================\n",
    "def identify_speakers_force_choice(\n",
    "    dialogues: List[Dict[str, str]],\n",
    "    profile_text: str,\n",
    "    performer_names: List[str],\n",
    "    llm: ChatGoogleGenerativeAI,\n",
    "    cache_path: str,\n",
    ") -> Dict[str, Dict[str, Any]]:\n",
    "    cached = load_mapping_cache(cache_path)  # 캐시 로드\n",
    "    if cached:  # 캐시가 있으면\n",
    "        return cached  # 그대로 반환\n",
    "\n",
    "    speaker_samples = build_speaker_samples(dialogues, max_samples=20, min_len=20)  # 샘플 생성\n",
    "\n",
    "    samples_str = \"\"  # 문자열\n",
    "    for sid, texts in speaker_samples.items():  # 반복\n",
    "        samples_str += f\"[{sid} 샘플]\\n\" + \"\\n\".join(texts) + \"\\n\\n\"  # 합치기\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"너는 연애 리얼리티 프로그램 분석가야.\\n\"\n",
    "         \"각 SPEAKER_XX가 아래 후보 중 누구인지 반드시 1명으로 결정해.\\n\"\n",
    "         \"중요 규칙:\\n\"\n",
    "         f\"- real_name은 반드시 {performer_names} 중 하나만 반환해. (Unknown 금지)\\n\"\n",
    "         \"- 확신이 낮아도 '가장 그럴듯한 쪽'을 선택해.\\n\"\n",
    "         \"- 대신 confidence(0~1)로 불확실함을 반드시 표시해.\\n\"\n",
    "         \"- reason에는 근거 단서가 있으면 쓰고, 단서가 부족하면 '단서 부족/중립 발화'라고 적어.\\n\\n\"\n",
    "         f\"[출연진 정보]\\n{profile_text}\"\n",
    "        ),\n",
    "        (\"user\", \"{samples_str}\")\n",
    "    ])\n",
    "\n",
    "    structured = llm.with_structured_output(schema=SpeakerMappingList)  # 구조화\n",
    "    result = structured.invoke(prompt.invoke({\"samples_str\": samples_str}))  # 실행\n",
    "\n",
    "    mapping_obj = {}  # 캐시에 저장할 구조\n",
    "    for m in result.mappings:  # 반복\n",
    "        mapping_obj[m.speaker_id] = {  # speaker별 저장\n",
    "            \"name\": m.real_name,  # 이름\n",
    "            \"confidence\": m.confidence,  # 확신도\n",
    "            \"reason\": m.reason,  # 근거\n",
    "        }\n",
    "\n",
    "    save_mapping_cache(cache_path, mapping_obj)  # 캐시 저장\n",
    "    return mapping_obj  # 반환\n",
    "\n",
    "# =========================\n",
    "# 7) 대화 분석(Gemini): LLM 1회 생성 후 재사용\n",
    "# =========================\n",
    "def analyze_dialogue_with_ai(\n",
    "    dialogue_text: str,\n",
    "    current_speaker: str,\n",
    "    config_text: str,\n",
    "    performer_names: List[str],\n",
    "    llm: ChatGoogleGenerativeAI,\n",
    ") -> Optional[DialogueAnalysis]:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"너는 대화 분석기야.\\n\"\n",
    "         \"화자({current_speaker})의 말을 분석해서 (1) 대상 인물, (2) 감정, (3) 발화 유형을 분류해.\\n\"\n",
    "         \"중요: target_person은 후보 목록에 있는 이름만 선택해. 애매하면 'None'.\\n\"\n",
    "         \"분석 기준: {analysis_config_text}\\n\"\n",
    "         \"대상 인물 후보: {performer_names}\"\n",
    "        ),\n",
    "        (\"user\", \"{dialogue_text}\")\n",
    "    ])\n",
    "\n",
    "    structured = llm.with_structured_output(schema=DialogueAnalysis)  # 구조화\n",
    "\n",
    "    try:\n",
    "        return structured.invoke(prompt.invoke({\n",
    "            \"current_speaker\": current_speaker,\n",
    "            \"analysis_config_text\": config_text,\n",
    "            \"performer_names\": performer_names,\n",
    "            \"dialogue_text\": dialogue_text,\n",
    "        }))\n",
    "    except ValidationError as e:\n",
    "        print(f\"Validation Error: speaker={current_speaker}, text={dialogue_text[:50]}...\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        msg = str(e)\n",
    "        print(f\"Unexpected Error: speaker={current_speaker}, text={dialogue_text[:50]}...\")\n",
    "        print(f\"Error details: {msg}\")\n",
    "        if \"PERMISSION_DENIED\" in msg or \"leaked\" in msg:\n",
    "            raise RuntimeError(\"❌ API 키가 차단되었습니다. 새 키 발급 후 .env 교체하세요.\")\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# 8) 한 케이스 실행\n",
    "#    - mode=\"pair\": 후보 2명, 결과도 2명만 저장\n",
    "#    - mode=\"all\": 후보 전체 출연진, 결과도 전체 저장\n",
    "# =========================\n",
    "def run_case(\n",
    "    case_name: str,\n",
    "    transcript_path: str,\n",
    "    performer_names: List[str],\n",
    "    config_path: str,\n",
    "    profile_path: str,\n",
    "    out_dir: str,\n",
    "    mode: str = \"pair\",\n",
    ") -> None:\n",
    "    print(f\"\\n===== RUN CASE: {case_name} ({mode}) =====\")  # 로그\n",
    "\n",
    "    dialogues = parse_transcript(transcript_path)  # 파싱\n",
    "    print(f\"Parsed segments: {len(dialogues)}\")  # 로그\n",
    "\n",
    "    config = load_config(config_path)  # config 로드\n",
    "\n",
    "    # ✅ 1) Regex 결과 저장\n",
    "    regex_result = analyze_text_regex(dialogues, config)  # regex 분석\n",
    "    regex_out_path = os.path.join(out_dir, f\"{case_name}_{mode}_regex.json\")  # 경로\n",
    "    save_json(regex_result, regex_out_path)  # 저장\n",
    "    print(f\"✅ Regex JSON saved: {regex_out_path}\")  # 로그\n",
    "\n",
    "    # ✅ 2) Gemini 준비\n",
    "    profile_df = pd.read_csv(profile_path)  # 프로필 로드\n",
    "    profile_text = profile_df.to_string(index=False)  # 텍스트화\n",
    "    analysis_config_text = json.dumps(config, ensure_ascii=False)  # 문자열화\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, google_api_key=GEMINI_API_KEY)  # LLM 1회 생성\n",
    "\n",
    "    # ✅ 3) 화자 매핑(Unknown 금지)\n",
    "    mapping_cache_path = os.path.join(out_dir, f\"{case_name}_{mode}_speaker_mapping.json\")  # 캐시 경로\n",
    "    mapping_obj = identify_speakers_force_choice(dialogues, profile_text, performer_names, llm, mapping_cache_path)  # 매핑\n",
    "    print(f\"✅ Speaker mapping cached: {mapping_cache_path}\")  # 로그\n",
    "\n",
    "    # ✅ 4) 대사 분석 결과 저장(CSV)\n",
    "    csv_out_path = os.path.join(out_dir, f\"{case_name}_{mode}_ai.csv\")  # CSV 경로\n",
    "    results = []  # 결과\n",
    "    processed_count = 0  # 재개\n",
    "\n",
    "    if os.path.exists(csv_out_path):\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_out_path)\n",
    "            processed_count = len(existing_df)\n",
    "            results = existing_df.to_dict(\"records\")\n",
    "            print(f\"Resume CSV: {processed_count} rows\")  # 로그\n",
    "        except Exception as e:\n",
    "            print(f\"Existing CSV read error, start fresh: {e}\")  # 로그\n",
    "\n",
    "    # ✅ mode별 저장 기준\n",
    "    target_set = set(performer_names)  # 후보 집합\n",
    "    save_only_targets = (mode == \"pair\")  # pair면 후보 2명만 저장\n",
    "\n",
    "    for i, d in enumerate(tqdm(dialogues)):\n",
    "        if i < processed_count:\n",
    "            continue\n",
    "\n",
    "        sid = d[\"speaker\"]  # SPEAKER ID\n",
    "        speaker_name = mapping_obj.get(sid, {}).get(\"name\")  # 매핑 이름\n",
    "        speaker_conf = mapping_obj.get(sid, {}).get(\"confidence\")  # 확신도\n",
    "\n",
    "        if not speaker_name:  # 혹시 누락되면\n",
    "            continue  # 스킵\n",
    "\n",
    "        if save_only_targets and speaker_name not in target_set:  # pair모드에서는 후보 2명만\n",
    "            continue\n",
    "\n",
    "        analysis = analyze_dialogue_with_ai(d[\"text\"], speaker_name, analysis_config_text, performer_names, llm)\n",
    "        if not analysis:\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"speaker\": speaker_name,\n",
    "            \"speaker_confidence\": speaker_conf,\n",
    "            \"text\": d[\"text\"],\n",
    "            \"target\": analysis.target_person,\n",
    "            \"sentiment\": analysis.sentiment,\n",
    "            \"category\": analysis.category,\n",
    "            \"summary\": analysis.summary,\n",
    "        })\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            pd.DataFrame(results).to_csv(csv_out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    pd.DataFrame(results).to_csv(csv_out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ Gemini CSV saved: {csv_out_path}\")\n",
    "\n",
    "# =========================\n",
    "# 9) main: 2커플 + 전체출연진 모드까지 실행\n",
    "# =========================\n",
    "def main():\n",
    "    config_path = \"/content/drive/MyDrive/project_team1/table/all_text_anlst.json\"\n",
    "    profile_path = \"/content/drive/MyDrive/project_team1/table/character_profile.csv\"\n",
    "    out_dir = \"/content/drive/MyDrive/project_team1/result\"\n",
    "\n",
    "    profile_df = pd.read_csv(profile_path)  # 전체 출연진 로드\n",
    "    all_performers = profile_df[\"name\"].dropna().unique().tolist()  # 전체 후보 리스트\n",
    "\n",
    "    # ✅ 1) 커플 2명 모드: 희두/나연\n",
    "    run_case(\n",
    "        case_name=\"환연2_희두나연\",\n",
    "        transcript_path=\"/content/drive/MyDrive/project_team1/transcript/환연2_희두나연.txt\",\n",
    "        performer_names=[\"남희두\", \"이나연\"],\n",
    "        config_path=config_path,\n",
    "        profile_path=profile_path,\n",
    "        out_dir=out_dir,\n",
    "        mode=\"pair\",\n",
    "    )\n",
    "\n",
    "    # ✅ 2) 커플 2명 모드: 해은/규민\n",
    "    run_case(\n",
    "        case_name=\"환연2_해은규민\",\n",
    "        transcript_path=\"/content/drive/MyDrive/project_team1/transcript/환연2_해은규민.txt\",\n",
    "        performer_names=[\"성해은\", \"정규민\"],\n",
    "        config_path=config_path,\n",
    "        profile_path=profile_path,\n",
    "        out_dir=out_dir,\n",
    "        mode=\"pair\",\n",
    "    )\n",
    "\n",
    "    # ✅ 3) 전체 출연진 모드(10명+)\n",
    "    run_case(\n",
    "        case_name=\"환연2_전체\",\n",
    "        transcript_path=\"/content/drive/MyDrive/project_team1/transcript/환연2_1화_20화_요약.txt\",\n",
    "        performer_names=all_performers,\n",
    "        config_path=config_path,\n",
    "        profile_path=profile_path,\n",
    "        out_dir=out_dir,\n",
    "        mode=\"all\",\n",
    "    )\n",
    "   \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
